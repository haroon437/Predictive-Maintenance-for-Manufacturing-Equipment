{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d861b-cc8b-46f9-9c65-99bc52035655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required Libraries \n",
    "!pip install pandas numpy seaborn matplotlib scipy scikit-learn openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f998a6-89f9-44e4-a3c5-7f190f1dfdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns   \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ced02d79-e310-4504-8588-98e8b5219a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading csv files for data-cleaning\n",
    "df_sensor = pd.read_csv('sensor_readings.csv')\n",
    "df_maintenance = pd.read_csv('maintenance_logs.csv')\n",
    "df_machine_excel = pd.read_excel('machine_metadata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee787e-851f-4207-bad2-7efe3ecaf5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Sensor dataset overview\n",
    "df_sensor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e0227-25ef-4274-8f4f-e1c91f70614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Maintenance dataset overview\n",
    "df_maintenance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f14df-82a6-458b-ac4c-12038dac248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Machine dataset overview\n",
    "df_machine.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decc284-5451-4daf-92a8-ca9a749fcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dtypes of Machine dataset overview\n",
    "df_sensor.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1aa6e832-420d-4dab-a850-b4449f8a9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Timestamp to datetime and extract date\n",
    "df_sensor['Timestamp'] = pd.to_datetime(df_sensor['Timestamp'])\n",
    "df_sensor['Date'] = df_sensor['Timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d756db-8b18-4415-9307-2d05f5a90736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Checking again the dtypes of Machine dataset after converting to date\n",
    "df_sensor.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9ed5d-9f4a-43b7-861d-eb24da49ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by date and calculate daily averages\n",
    "daily_avg = cleaned_sensor_readings.groupby('Date').agg({\n",
    "    'Temperature (°C)': 'mean',\n",
    "    'Vibration (mm/s)': 'mean',\n",
    "    'Pressure (psi)': 'mean',\n",
    "    'RuntimeHours': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(daily_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb054e52-c3b8-454a-adee-3feb54beac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many missing value in sensor dataset\n",
    "df_sensor.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b616469-3445-4a35-b80f-0fe446e9e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing value in sensor dataset with median\n",
    "df_sensor['Vibration (mm/s)'].fillna(df_sensor['Vibration (mm/s)'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a9c533c-52ba-49c6-8745-66eb6076e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting outliers using IQR \n",
    "def detect_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1 \n",
    "    lower = Q1-1.5*IQR \n",
    "    higher = Q3+1.5*IQR \n",
    "    return series[(series>higher)|(series<lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c46cff9-3f06-4be9-9a14-50f317a0ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting outliers in Temperature column \n",
    "temp_outlier = detect_outliers(df_sensor['Temperature (°C)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd009c-065e-447d-b4ca-fcdb09492563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking How many outlier in temperature column\n",
    "print({\"Outlier_In_Temperature\": len(temp_outlier)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7893427b-ae3c-4781-82a0-0981ea56ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Removing Outliers from temperature column\n",
    "def remove_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1 \n",
    "    lower = Q1-1.5*IQR \n",
    "    higher = Q3+1.5*IQR \n",
    "    return series[(series>higher)|(series<lower)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9a5a390-2048-4e91-a843-99661e177c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing detected outlier in temperature column\n",
    "outlier_removed = remove_outliers(df_sensor['Temperature (°C)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "579a6a19-c70d-4de3-93d0-b4516de21e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing detected outlier in temperature column\n",
    "cleaned_sensor_readings = df_sensor.drop(outlier_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e66eb7b-fc38-4314-9986-1829ef83e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting old dataset to cleaned dataset\n",
    "cleaned_sensor_readings.to_csv('cleaned_sensor_readings.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442f857-8cac-476a-8100-9c18ba793855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dtypes of Maintenance dataset \n",
    "df_maintenance.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "60428456-2c5f-46fe-be92-4fb9277f257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting dtype of date in maintenance dataset\n",
    "\n",
    "# Define the function to try multiple date formats\n",
    "def try_parse_dates(date_str):\n",
    "    date_formats = ['%d-%m-%Y', '%Y-%m-%d', '%Y/%m/%d']\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            parsed_date = pd.to_datetime(date_str, format=fmt, errors='coerce')\n",
    "            if pd.notna(parsed_date):\n",
    "                return parsed_date\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "# Apply the function and ensure dtype conversion\n",
    "df_maintenance['Date'] = df_maintenance['Date'].apply(try_parse_dates)\n",
    "\n",
    "# Explicitly convert to datetime64[ns] to enforce dtype\n",
    "df_maintenance['Date'] = pd.to_datetime(df_maintenance['Date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf74067-7d06-4c57-a737-0418a0b558a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Checking again the dtypes of Maintenance dataset \n",
    "df_maintenance.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175752a1-fa9a-4bf3-9046-bd2c83d73419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking is there any missing value in maintenance dataset\n",
    "df_maintenance.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8653d48-0df5-4225-9578-89246db9f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values of RepairType in Maintenance dataset\n",
    "df_maintenance['RepairType'].fillna(df_maintenance['RepairType'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6cfa34fa-4752-461d-a19a-061c97a98fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting old dataset to cleaned dataset\n",
    "df_maintenance.to_csv('cleaned_maintenance_logs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173dfb8-149f-45c8-b639-7e0e67a3b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dtypes of Machine dataset \n",
    "df_machine_excel.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da58a7a-c042-4bf1-9bd2-c990ba67f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking is there any missing value in machine dataset\n",
    "df_machine_excel.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c182fb1-df17-4771-a5eb-75589bc3f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting days_since_last_overhaul feature using python\n",
    "\n",
    "# Merge with sensor readings\n",
    "df_merge = cleaned_sensor_readings.merge(df_machine_excel, on=\"MachineID\", how=\"left\")\n",
    "\n",
    "# Calculate 'DaysSinceOverhaul'\n",
    "df_merge[\"DaysSinceOverhaul\"] = (df_merge[\"Date\"] - df_merge[\"LastOverhaulDate\"]).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "14ed5a22-ccb6-4132-a187-2831dcfd7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing dtype of Date from object to datetime\n",
    "cleaned_sensor_readings['Date'] = pd.to_datetime(cleaned_sensor_readings['Date'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e477fc-dd83-4600-b121-9db52ba8a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the merge dataset to see DaysSinceOverhaul created\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aec66ac6-9c50-47b4-9f22-a0d41d556b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sqlite3 and making connection for database\n",
    "import sqlite3, csv \n",
    "con = sqlite3.connect('Maintenance.db')\n",
    "curr = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55b3a4-9d2d-43c2-a7d6-0e480f430916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pretty table library for to show tables when executing sql query\n",
    "!pip install ipython-sql pretty\n",
    "import prettytable\n",
    "prettytable.DEFAULT = 'DEFAULT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f1ac8-fffd-42e4-afc9-b7c27e42d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  loading the database\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d1e188fc-224f-4064-a09a-68c076354748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Connection to Database\n",
    "%sql sqlite:///Maintenance.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de322ecf-0a40-4041-934e-3f43e6a86559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading cleaned csv to sql and assigning name for table like Sensor Data\n",
    "cleaned_sensor_readings.to_sql('Sensor_Data',con,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016bb7d4-8d59-45d4-88ee-fb472a6819de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading cleaned csv to sql and assigning name for table like Maintenance Data\n",
    "cleaned_maintenance_logs.to_sql('Maintenance_Data',con,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bbcab-0d55-49af-ab8c-3144b2dc0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading cleaned csv to sql and assigning name for table like Maintenance Data\n",
    "df_machine_excel.to_sql('Machine_Data',con,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804cc87-f2d1-4883-b4bd-1fe1d3d228cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rolling averages of sensor feature using sql\n",
    "df_merge_sql = %sql SELECT *, \\\n",
    "                    (JULIANDAY(s.Date) - JULIANDAY(m.LastOverhaulDate)) AS DaysSinceOverhaul, \\\n",
    "                    AVG(s.Temperature) OVER ( \\\n",
    "                        PARTITION BY s.MachineID \\\n",
    "                        ORDER BY s.Timestamp \\\n",
    "                        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW \\\n",
    "                    ) AS Temp_3DayAvg, \\\n",
    "                    AVG(s.Vibration) OVER ( \\\n",
    "                        PARTITION BY s.MachineID \\\n",
    "                        ORDER BY s.Timestamp \\\n",
    "                        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW \\\n",
    "                    ) AS Vib_3DayAvg, \\\n",
    "                    AVG(s.Pressure) OVER ( \\\n",
    "                        PARTITION BY s.MachineID \\\n",
    "                        ORDER BY s.Timestamp \\\n",
    "                        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW \\\n",
    "                    ) AS Pres_3DayAvg \\\n",
    "                FROM Sensor_Data s \\\n",
    "                JOIN Machine_Data m ON s.MachineID = m.MachineID \\\n",
    "                ORDER BY s.MachineID, s.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77854b2b-6b85-4227-8189-a9e3a145d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_sql = df_merge_sql.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc12be-5422-41b5-ac89-bb554f3dcb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0275aae0-e90b-4eaf-8d5f-48648a9ccf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.rename(columns={'Temperature (°C)':'Temperature','Vibration (mm/s)':'Vibration','Pressure (psi)':'Pressure'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a9beb2-7417-4de9-a233-29738c31daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rolling averages of sensor feature using python\n",
    "df_merge = df_merge.sort_values(by=[\"MachineID\", \"Timestamp\"])\n",
    "\n",
    "# Define rolling window (3 observations here, assuming daily or near-daily frequency)\n",
    "df_merge[\"Temp_3DayAvg\"] = df_merge.groupby(\"MachineID\")[\"Temperature\"]\\\n",
    "                                   .transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "\n",
    "df_merge[\"Vib_3DayAvg\"] = df_merge.groupby(\"MachineID\")[\"Vibration\"]\\\n",
    "                                  .transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "\n",
    "df_merge[\"Pres_3DayAvg\"] = df_merge.groupby(\"MachineID\")[\"Pressure\"]\\\n",
    "                                   .transform(lambda x: x.rolling(window=3, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692b1d1-8a14-457b-9b0b-f7dc1912e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05afac18-0b51-4590-9025-22a2c53bb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dtype of Date column in maintenance dataset to datetime and also filter out the failure = Y from maintenance dataset\n",
    "cleaned_maintenance_logs[\"Date\"] = pd.to_datetime(cleaned_maintenance_logs[\"Date\"])\n",
    "df_maintenance_failure = cleaned_maintenance_logs[cleaned_maintenance_logs[\"Failure\"] == \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb2b8dc4-0385-447d-b8f1-07512dcde8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def check_failure_within_30_days(row):\n",
    "    machine_id = row[\"MachineID\"]\n",
    "    current_date = row[\"Date\"]\n",
    "    future_failures = df_maintenance_failure[\n",
    "        (df_maintenance_failure[\"MachineID\"] == machine_id) &\n",
    "        (df_maintenance_failure[\"Date\"] > current_date) &\n",
    "        (df_maintenance_failure[\"Date\"] <= current_date + timedelta(days=30))\n",
    "    ]\n",
    "    return 1 if not future_failures.empty else 0\n",
    "\n",
    "df_merge[\"FailureNext30Days\"] = df_merge.apply(check_failure_within_30_days, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2543aba-ed6a-4d71-883a-e61b903a85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features to use (update this list with your final engineered features)\n",
    "feature_cols = [\"Temperature\", \"Vibration\", \"Pressure\", \"RuntimeHours\",\n",
    "                \"DaysSinceOverhaul\", \"Temp_3DayAvg\", \"Vib_3DayAvg\", \"Pres_3DayAvg\"]\n",
    "\n",
    "X = df_merge[feature_cols]\n",
    "y = df_merge[\"FailureNext30Days\"]\n",
    "\n",
    "# Drop rows with any remaining NaNs\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7d1cd-50bd-4b15-b855-17288d4d2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e76445-5016-4469-a374-1b4933216c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_prob))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve (AUC = {:.2f})\".format(roc_auc_score(y_test, y_prob)))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d9b33-f09d-4bb3-aa5b-1afe1e845df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create DataFrame of features and their importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": rf_model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance, palette=\"viridis\")\n",
    "\n",
    "# Add importance values on each bar\n",
    "for i, (importance, feature) in enumerate(zip(feature_importance[\"Importance\"], feature_importance[\"Feature\"])):\n",
    "    ax.text(importance + 0.0001, i, f\"{importance:.3f}\", va='center', ha='left', fontsize=9)\n",
    "\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18b23a27-3a77-44e3-84b2-41827a5f1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure FailureProbability is already added\n",
    "df_sorted = df_merge.sort_values([\"MachineID\", \"Timestamp\"], ascending=[True, False])\n",
    "\n",
    "# Keep only the latest record per machine\n",
    "latest_status = df_sorted.groupby(\"MachineID\").first().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1babf46-8df6-4017-8529-afd63c715640",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk = latest_status[latest_status[\"FailureProbability\"] > 0.7].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7084025-9f2c-41b9-a18f-cd88c831897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "high_risk[\"RecommendedMaintenanceDate\"] = high_risk[\"Date\"] + high_risk[\"FailureProbability\"].apply(\n",
    "    lambda p: timedelta(days=int(np.interp(p, [0.7, 1.0], [7, 14])))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88801b5d-b94c-4ed7-af8c-00f0ae3a0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance_recommendations = high_risk[[\n",
    "    \"MachineID\", \"Date\", \"FailureProbability\", \"RecommendedMaintenanceDate\"\n",
    "]].sort_values(by=\"FailureProbability\", ascending=False)\n",
    "\n",
    "maintenance_recommendations[\"FailureProbability\"] = maintenance_recommendations[\"FailureProbability\"].round(3)\n",
    "maintenance_recommendations[\"RecommendedMaintenanceDate\"] = maintenance_recommendations[\"RecommendedMaintenanceDate\"].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b36d4-ddc1-4ba2-a147-a2052845d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance_recommendations.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
